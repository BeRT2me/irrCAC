
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>irrCAC package &#8212; irrCAC 0.1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="irrCAC" href="modules.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="irrcac-package">
<h1>irrCAC package<a class="headerlink" href="#irrcac-package" title="Permalink to this headline">¶</a></h1>
<section id="module-irrCAC">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-irrCAC" title="Permalink to this headline">¶</a></h2>
<p>Inter-rater reliability</p>
<p>In statistics, inter-rater reliability (also called by various similar names,
such as inter-rater agreement, inter-rater concordance, inter-observer
reliability, and so on) is the degree of agreement among raters. It is a score
of how much homogeneity or consensus exists in the ratings given by various
judges.</p>
<p>There are a number of statistics that can be used to determine inter-rater
reliability. Different statistics are appropriate for different types of
measurement. Some options are</p>
<ul class="simple">
<li><p>joint-probability of agreement</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen’s kappa</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Scott%27s_pi">Scott’s pi</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Fleiss%27_kappa">Fleiss’ kappa</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Krippendorff%27s_alpha">Krippendorff’s alpha</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Concordance_correlation_coefficient">Concordance Correlation Coefficient</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Intraclass_correlation">Intra-Class Correlation</a></p></li>
</ul>
<p>and many others.</p>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</section>
<section id="module-irrCAC.benchmark">
<span id="irrcac-benchmark-module"></span><h2>irrCAC.benchmark module<a class="headerlink" href="#module-irrCAC.benchmark" title="Permalink to this headline">¶</a></h2>
<p>The “Cumulative Probability” approach to Benchmarking.</p>
<dl class="py class">
<dt class="sig sig-object py" id="irrCAC.benchmark.Benchmark">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">irrCAC.benchmark.</span></span><span class="sig-name descname"><span class="pre">Benchmark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">coeff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.benchmark.Benchmark" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Compute benchmark scale membership probabilities.</p>
<p>An elaborate approach to interpret a kappa value is based on the notion of
cumulative interval membership probability (CIMP). The interval probability
represents the Normality-based probability that the “true” agreement
coefficient kappa belongs to the interval in question and is calculated
based on <span class="math notranslate nohighlight">\(\hat{\kappa}\)</span> and an arbitrary interval <span class="math notranslate nohighlight">\((a, b)\)</span> as
follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(a \le \kappa_1 \le b)
    &amp;= P[(\hat{\kappa}_1 - b)/se(\hat{\kappa}_1)
       \le Z \le
       (\hat{\kappa}_1 - a)/se(\hat{\kappa}_1)] \\
    &amp;= \Phi[(\hat{\kappa}_1 - b)/se(\hat{\kappa}_1)] -
       \Phi[(\hat{\kappa}_1 - a)/se(\hat{\kappa}_1)]\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Phi\)</span> is the cumulative distribution function of the standard
Normal distribution. The general rule consists of retaining the highest
interval whose CIMP equals or exceeds the threshold of 0.95. For more
details see <a class="reference external" href="https://inter-rater-reliability.blogspot.com/2018/02/">Inter-rater reliability among multiple raters when subjects
are rated by different pairs of subjects.</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>coeff</strong> (<em>float</em>) – A floating number representing the estimated value of an agreement
coefficient.</p></li>
<li><p><strong>se</strong> (<em>float</em>) – The coefficient standard error.</p></li>
</ul>
</dd>
</dl>
<div class="admonition-examples admonition">
<p class="admonition-title">Examples</p>
<p>Using the following example, for kappa 0.67 and standard error 0.15,
it is recommended to consider the agreement as moderate on the Altman scale.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">irrCAC.benchmark</span> <span class="kn">import</span> <span class="n">Benchmark</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span> <span class="o">=</span> <span class="n">Benchmark</span><span class="p">(</span><span class="n">coeff</span><span class="o">=</span><span class="mf">0.67</span><span class="p">,</span> <span class="n">se</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark</span><span class="o">.</span><span class="n">altman</span><span class="p">())</span>  
<span class="go">{&#39;scale&#39;: [(0.8, 1.0), (0.6, 0.8), (0.4, 0.6), (0.2, 0.4), (-1.0, 0.2)],</span>
<span class="go">&#39;Altman&#39;: [&#39;Very Good&#39;, &#39;Good&#39;, &#39;Moderate&#39;, &#39;Fair&#39;, &#39;Poor&#39;],</span>
<span class="go">&#39;CumProb&#39;: [0.18168, 0.67511, 0.96356, 0.99912, 1.0]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_scale</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>        <span class="n">lb</span><span class="o">=</span><span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>        <span class="n">ub</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>        <span class="n">interp</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Excellent&#39;</span><span class="p">,</span> <span class="s1">&#39;Acceptable&#39;</span><span class="p">,</span> <span class="s1">&#39;Poor&#39;</span><span class="p">],</span>        <span class="n">scale_name</span><span class="o">=</span><span class="s1">&#39;My Scale&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark</span><span class="o">.</span><span class="n">interpret</span><span class="p">(</span><span class="n">my_scale</span><span class="p">))</span>  
<span class="go">{&#39;scale&#39;: [(0.6, 1.0), (0.3, 0.6), (0.0, 0.3)],</span>
<span class="go">&#39;My Scale&#39;: [&#39;Excellent&#39;, &#39;Acceptable&#39;, &#39;Poor&#39;],</span>
<span class="go">&#39;CumProb&#39;: [0.67511, 0.99308, 1.0]}</span>
</pre></div>
</div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.benchmark.Benchmark.altman">
<span class="sig-name descname"><span class="pre">altman</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.benchmark.Benchmark.altman" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpret the level of agreement using the Altman benchmark scale.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 57%" />
<col style="width: 43%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Interpretation</p></th>
<th class="head"><p>Scale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Very Good</p></td>
<td><p>0.8 - 1.0</p></td>
</tr>
<tr class="row-odd"><td><p>Good</p></td>
<td><p>0.6 - 0.8</p></td>
</tr>
<tr class="row-even"><td><p>Moderate</p></td>
<td><p>0.4 - 0.6</p></td>
</tr>
<tr class="row-odd"><td><p>Fair</p></td>
<td><p>0.2 - 0.4</p></td>
</tr>
<tr class="row-even"><td><p>Poor</p></td>
<td><p>-1.0 - 0.2</p></td>
</tr>
</tbody>
</table>
<p>D. Altman. 1990. Practical statistics for medical research.
Chapman and Hall/CRC.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.benchmark.Benchmark.cicchetti_sparrow">
<span class="sig-name descname"><span class="pre">cicchetti_sparrow</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.benchmark.Benchmark.cicchetti_sparrow" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpret the level of agreement using the Cicchetti and Sparrow         benchmark scale.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 55%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Interpretation</p></th>
<th class="head"><p>Scale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Excellent</p></td>
<td><p>0.75 - 1.0</p></td>
</tr>
<tr class="row-odd"><td><p>Good</p></td>
<td><p>0.6  - 0.75</p></td>
</tr>
<tr class="row-even"><td><p>Fair</p></td>
<td><p>0.4  - 0.6</p></td>
</tr>
<tr class="row-odd"><td><p>Poor</p></td>
<td><p>0.0  - 0.4</p></td>
</tr>
</tbody>
</table>
<p>Cicchetti, D. V.; Sparrow, S. A. (1981). “Developing criteria for
establishing interrater reliability of specific items: applications to
assessment of adaptive behavior”. American Journal of Mental Deficiency.
86 (2): 127–137. ISSN 0002-9351. PMID 7315877.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.benchmark.Benchmark.fleiss">
<span class="sig-name descname"><span class="pre">fleiss</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.benchmark.Benchmark.fleiss" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpret the level of agreement using the Fleiss benchmark scale.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 55%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Interpretation</p></th>
<th class="head"><p>Scale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Excellent</p></td>
<td><p>0.75 - 1.0</p></td>
</tr>
<tr class="row-odd"><td><p>Fair to Good</p></td>
<td><p>0.4  - 0.75</p></td>
</tr>
<tr class="row-even"><td><p>Poor</p></td>
<td><p>0.0  - 0.4</p></td>
</tr>
</tbody>
</table>
<p>Fleiss, J. L. (1971). Measuring nominal scale agreement among many
raters. Psychological Bulletin, 76(5), 378</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.benchmark.Benchmark.interpret">
<span class="sig-name descname"><span class="pre">interpret</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bench</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.benchmark.Benchmark.interpret" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpret the agreement coefficient on a benchmark scale.</p>
<p>To interpret the agreement coefficient we see in which range the
cumulative probability exceeds 0.95. E.g., if we have a coefficient
value of 0.67 with standard error 0.15, we get the following
results.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 39%" />
<col style="width: 32%" />
<col style="width: 29%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Scale</p></th>
<th class="head"><p>Altman</p></th>
<th class="head"><p>CumProb</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>(0.8, 0.1)</p></td>
<td><p>Very Good</p></td>
<td><p>0.18168</p></td>
</tr>
<tr class="row-odd"><td><p>(0.6, 0.8)</p></td>
<td><p>Good</p></td>
<td><p>0.67511</p></td>
</tr>
<tr class="row-even"><td><p>(0.4, 0.6)</p></td>
<td><p>Moderate</p></td>
<td><p>0.96356</p></td>
</tr>
<tr class="row-odd"><td><p>(0.2, 0.4)</p></td>
<td><p>Fair</p></td>
<td><p>0.99912</p></td>
</tr>
<tr class="row-even"><td><p>(-1.0, 0.2)</p></td>
<td><p>Poor</p></td>
<td><p>1.0</p></td>
</tr>
</tbody>
</table>
<p>It is safer to say that we have a <em>Moderate</em> agreement (the first scale
that is &gt;= 0.95), than to say that we have a <em>Good</em> agreement (because
0.6 &lt;= 0.67 &lt;= 0.8). The reason for that is that we have a large
standard error.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bench</strong> (<em>dict</em>) – A dictionary with the lower and upper bounds of the scale, the
interpretation of each scale and a scale name.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A dict with three keys: Kappa intervals, Benchmark scale
interpretation, and Cumulative probability. For example:</p>
<p><code class="docutils literal notranslate"><span class="pre">{'scale':</span> <span class="pre">[</span>
<span class="pre">(0.8,</span> <span class="pre">1.0),</span> <span class="pre">(0.6,</span> <span class="pre">0.8),</span> <span class="pre">(0.4,</span> <span class="pre">0.6),</span> <span class="pre">(0.2,</span> <span class="pre">0.4),</span> <span class="pre">(-1.0,</span> <span class="pre">0.2)],</span>
<span class="pre">'Altman':</span> <span class="pre">['Very</span> <span class="pre">Good',</span> <span class="pre">'Good',</span> <span class="pre">'Moderate',</span> <span class="pre">'Fair',</span> <span class="pre">'Poor'],</span>
<span class="pre">'CumProb':</span> <span class="pre">[0.18168,</span> <span class="pre">0.67511,</span> <span class="pre">0.96356,</span> <span class="pre">0.99912,</span> <span class="pre">1.0]}</span></code></p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.benchmark.Benchmark.landis_koch">
<span class="sig-name descname"><span class="pre">landis_koch</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.benchmark.Benchmark.landis_koch" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpret the level of agreement using the Landis-Koch benchmark         scale.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 57%" />
<col style="width: 43%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Interpretation</p></th>
<th class="head"><p>Scale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Almost Perfect</p></td>
<td><p>0.8 - 1.0</p></td>
</tr>
<tr class="row-odd"><td><p>Substantial</p></td>
<td><p>0.6 - 0.8</p></td>
</tr>
<tr class="row-even"><td><p>Moderate</p></td>
<td><p>0.4 - 0.6</p></td>
</tr>
<tr class="row-odd"><td><p>Fair</p></td>
<td><p>0.2 - 0.4</p></td>
</tr>
<tr class="row-even"><td><p>Slight</p></td>
<td><p>0.0 - 0.2</p></td>
</tr>
<tr class="row-odd"><td><p>Poor</p></td>
<td><p>-1.0 - 0.0</p></td>
</tr>
</tbody>
</table>
<p>Landis, J. Richard; Koch, Gary G. (1977). “The Measurement of Observer
Agreement for Categorical Data”. Biometrics. 33 (1): 159–74.
doi:10.2307/2529310. ISSN 0006-341X.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.benchmark.Benchmark.regier">
<span class="sig-name descname"><span class="pre">regier</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.benchmark.Benchmark.regier" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpret the level of agreement using the Regier et al. benchmark         scale.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 57%" />
<col style="width: 43%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Interpretation</p></th>
<th class="head"><p>Scale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Excellent</p></td>
<td><p>0.8 - 1.0</p></td>
</tr>
<tr class="row-odd"><td><p>Very Good</p></td>
<td><p>0.6 - 0.8</p></td>
</tr>
<tr class="row-even"><td><p>Good</p></td>
<td><p>0.4 - 0.6</p></td>
</tr>
<tr class="row-odd"><td><p>Questionable</p></td>
<td><p>0.2 - 0.4</p></td>
</tr>
<tr class="row-even"><td><p>Unacceptable</p></td>
<td><p>0.0 - 0.2</p></td>
</tr>
</tbody>
</table>
<p>Regier, Darrel A.; Narrow, William E.; Clarke, Diana E.; Kraemer,
Helena C.; Kuramoto, S. Janet; Kuhl, Emily A.; Kupfer, David J. (2013).
“DSM-5 Field Trials in the United States and Canada, Part II:
Test-Retest Reliability of Selected Categorical Diagnoses”.
American Journal of Psychiatry. 170 (1): 59–70.
doi:10.1176/appi.ajp.2012.12070999. ISSN 0002-953X. PMID 23111466</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-irrCAC.datasets">
<span id="irrcac-datasets-module"></span><h2>irrCAC.datasets module<a class="headerlink" href="#module-irrCAC.datasets" title="Permalink to this headline">¶</a></h2>
<p>Sample datasets for demonstrating and testing agreement coefficients.</p>
<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.dist_4cat">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">dist_4cat</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.dist_4cat" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribution of 4 raters by Category and Subject - Subjects allocated     in 2 groups A and B.</p>
<p>This dataset summarizes the ratings assigned by 4 raters who classified 15
subjects into one of 3 categories named “a”, “b”, and “c”.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Group</dt><dd><p>This variable represents the group name.</p>
</dd>
<dt>a</dt><dd><p>Number of ratings in category “a”</p>
</dd>
<dt>b</dt><dd><p>Number of ratings in category “b”</p>
</dd>
<dt>c</dt><dd><p>Number of ratings in category “c”</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.dist_g1g2">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">dist_g1g2</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.dist_g1g2" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribution of 4 raters by subject and by category, for 14 Subjects     that belong to 2 groups “G1” and “G2”.</p>
<p>This dataset contains rating data in the form of a subject-level
distribution of 4 raters by category the subject was classified into.
A total of 4 raters had to classify 14 subjects into one of 5 categories
“a”, “b”, “c”, “d”, and “e”. None of the 4 raters scored all 14 units.
Therefore, some missing ratings appear in each of the columns associated
with the 4 raters.</p>
<p>This dataset is different version of the more detailed <cite>raw_g1g2</cite> dataset.
While <cite>raw_g1g2</cite> tells you about the exact category into which each rater
classified all subjects, this one on the other hand, can only tell you how
many raters classified a given subject into a particular category.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">datasets.raw_g1g2</span></code></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Group</dt><dd><p>This variable represents the group name.</p>
</dd>
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>a</dt><dd><p>Number of raters who classified the subject represented by the row
into category “a”</p>
</dd>
<dt>b</dt><dd><p>Number of raters who classified the subject represented by the row
into category “b”</p>
</dd>
<dt>c</dt><dd><p>Number of raters who classified the subject represented by the row
into category “c”</p>
</dd>
<dt>d</dt><dd><p>Number of raters who classified the subject represented by the row
into category “d”</p>
</dd>
<dt>e</dt><dd><p>Number of raters who classified the subject represented by the row
into category “e”</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.distrib_6raters">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">distrib_6raters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.distrib_6raters" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribution of 6 psychiatrists by Subject/patient and diagnosis     category.</p>
<p>This dataset summarizes the ratings assigned by 6 psychiatrists classifying
15 patients into one of five categories named “Depression”, “Personal
Disorder”, “Schizophrenia”, “Neurosis” and “Other.</p>
<p><strong>Source:</strong> Fleiss, J. L. (1971). Measuring nominal scale agreement among
many raters, Psychological Bulletin, 76, 378-382.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>Depression</dt><dd><p>The number of raters assigned the subject to the depression category</p>
</dd>
<dt>Personality Disorder</dt><dd><p>The number of raters assigned the subject to the personality
disorder category</p>
</dd>
<dt>Schizophrenia</dt><dd><p>The number of raters assigned the subject to the schizophrenia
category</p>
</dd>
<dt>Neurosis</dt><dd><p>The number of raters assigned the subject to the neurosis category</p>
</dd>
<dt>Other</dt><dd><p>The number of raters assigned the subject to the other category</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.raw_4raters">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">raw_4raters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.raw_4raters" title="Permalink to this definition">¶</a></dt>
<dd><p>Rating Data from 4 Raters and 12 Subjects.</p>
<p>This dataset contains ratings obtained from an experiment where 4 raters
classified 12 subjects into 5 possible categories labeled as 1, 2, 3, 4,
and 5. None of the 4 raters scored all 12 units. Therefore, some missing
ratings in the form of “NA” appear in each of the columns associated with
the 4 raters. Note that only the 4 last columns are to be used with the
functions included in this package. The first column only plays a
descriptive role and is not used in any calculation.</p>
<p><strong>Source</strong>: Gwet, K.L. (2014) Handbook of Inter-Rater Reliability,
4th Edition, page #120. Advanced Analytics, LLC</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>The data frame has the following columns:</p>
<dl class="simple">
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>Rater1</dt><dd><p>All ratings from rater 1</p>
</dd>
<dt>Rater2</dt><dd><p>All ratings from rater 2</p>
</dd>
<dt>Rater3</dt><dd><p>All ratings from rater 3</p>
</dd>
<dt>Rater4</dt><dd><p>All ratings from rater 4</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.raw_5observers">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">raw_5observers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.raw_5observers" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores assigned by 5 observers to 20 experimental units.</p>
<p>This dataset contains data from a reliability experiment where 5 observers
scored 15 units on a 4-point numeric scale based on the values
0, 1, 2 and 3.</p>
<p>The dataset has 15 rows (for the 15 subjects) and 6 columns.
Only the last 5 columns associated with the 5 observers are used in the
calculations. Of the 5 observers, only observer 3 scored all 15 units.
Therefore, some missing ratings in the form of “NA” appear in the columns
associated with the remaining 4 observers.</p>
<p><strong>Source</strong>: Gwet, K.L. (2014) Handbook of Inter-Rater Reliability,
4th Edition. Advanced Analytics, LLC.
A larger version of this table can be found on page #125</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>The data frame has the following columns:</p>
<dl class="simple">
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>Observer1</dt><dd><p>All ratings from observer 1</p>
</dd>
<dt>Observer2</dt><dd><p>All ratings from observer 2</p>
</dd>
<dt>Observer3</dt><dd><p>All ratings from observer 3</p>
</dd>
<dt>Observer4</dt><dd><p>All ratings from observer 4</p>
</dd>
<dt>Observer5</dt><dd><p>All ratings from observer 5</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.raw_ben_gerry">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">raw_ben_gerry</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.raw_ben_gerry" title="Permalink to this definition">¶</a></dt>
<dd><p>Ratings of 12 units from 2 raters named Ben and Gerry.</p>
<p>This dataset contains ratings that 2 raters named Ben and Gerry assigned to
12 units distributed in 2 groups “G1” and “G2”. Each row of this dataset
describes an interval and the interpretation of the magnitude it represents.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>The data frame has the following columns:</p>
<dl class="simple">
<dt>Group</dt><dd><p>This variable represents the group membership.</p>
</dd>
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>Ben</dt><dd><p>All ratings from Ben</p>
</dd>
<dt>Gerry</dt><dd><p>All ratings from Gerry</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.Dataframe</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.raw_g1g2">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">raw_g1g2</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.raw_g1g2" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset of raw ratings from 4 Raters on 14 Subjects that belong to 2     groups “G1” and “G2”.</p>
<p>This dataset contains data from a reliability experiment where 4 raters
identified as Rater1, Rater2, Rater3 and Rater4 scored 14 units on a
5-point alphabetical scale based on the values a, b, c, d and e.
These 14 units are allocated to 2 groups named G1 and G2</p>
<p>This dataset contains ratings obtained from an experiment where 4 raters
classified 14 subjects into 5 possible categories labeled as a, b, c, d,
and e. None of the 4 raters scored all 14 units. Therefore, some missing
ratings appear in each of the columns associated with the 4 raters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>The data frame has the following columns:</p>
<dl class="simple">
<dt>Group</dt><dd><p>This variable represents the group membership.</p>
</dd>
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>Rater1</dt><dd><p>All ratings from rater 1</p>
</dd>
<dt>Rater2</dt><dd><p>All ratings from rater 2</p>
</dd>
<dt>Rater3</dt><dd><p>All ratings from rater 3</p>
</dd>
<dt>Rater4</dt><dd><p>All ratings from rater 4</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.raw_gender">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">raw_gender</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.raw_gender" title="Permalink to this definition">¶</a></dt>
<dd><p>Rating Data from 4 Raters and 15 human Subjects, 9 of whom are female     and 6 males.</p>
<p>This dataset contains data from a reliability experiment where 4 raters
scored 15 units on a 3-point alphabetic scale based on the values
a, b, and c.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>The data frame has the following columns:</p>
<dl class="simple">
<dt>Group</dt><dd><p>This variable represents the group membership.</p>
</dd>
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>Rater1</dt><dd><p>All ratings from rater 1</p>
</dd>
<dt>Rater2</dt><dd><p>All ratings from rater 2</p>
</dd>
<dt>Rater3</dt><dd><p>All ratings from rater 3</p>
</dd>
<dt>Rater4</dt><dd><p>All ratings from rater 4</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.table_cont3x3abstractors">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">table_cont3x3abstractors</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.table_cont3x3abstractors" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribution of 100 pregnant women by pregnancy type and by abstractor.</p>
<p>This dataset contains pregnancy type data collected from 100 women who
entered an Emergency Room with a positive pregnancy test and a second
condition, which is either abdominal pain or vaginal bleeding. After
reviewing their medical records, 2 reviewers (also referred to as
abstractors) classified them into one of the following three pregnancy
categories: Ectopic Pregnancy (Ectopic), Abnormal Intrauterine pregnancy
(AIU) and Normal Intrauterine Pregnancy (NIU).</p>
<p>Each row of this dataset describes an interval and the interpretation of
the magnitude it represents.</p>
<p><strong>Source:</strong> Gwet, K.L. (2014). Handbook of Inter-Rater Reliability,
4th Edition. Advanced Analytics, LLC.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Ectopic</dt><dd><p>Ectopic Pregnancy</p>
</dd>
<dt>AIU</dt><dd><p>Abnormal Intrauterine Pregnancy</p>
</dd>
<dt>NIU</dt><dd><p>Normal Intrauterine Pregnancy</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="irrCAC.datasets.table_cont4x4diagnosis">
<span class="sig-prename descclassname"><span class="pre">irrCAC.datasets.</span></span><span class="sig-name descname"><span class="pre">table_cont4x4diagnosis</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.datasets.table_cont4x4diagnosis" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribution of 223 Psychiatric Patients by Type of Psychiatric     Disorder and Diagnosis Method.</p>
<p>This dataset shows the distribution of 223 psychiatric patients by
diagnosis category and by the method used to obtain the diagnosis in a 4x4
squared table. The first method named “Clinical Diagnosis” (also known as
“Facility Diagnosis”) is used in a service facility (e.g. public hospital,
or a community unit) and does not rely on a rigorous application of
research criteria. The second method known as “Research Diagnosis” is based
on a strict application of research criteria. Column 1 contains the
diagnosis categories into which patients are classified with Method 1.
The first row on the other hand, shows categories into which patients are
classified with Method 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Method</dt><dd><p>The method used for the diagnosis.</p>
</dd>
<dt>Diagnosis</dt><dd><p>The category of the diagnosis.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-irrCAC.raw">
<span id="irrcac-raw-module"></span><h2>irrCAC.raw module<a class="headerlink" href="#module-irrCAC.raw" title="Permalink to this headline">¶</a></h2>
<p>Chance-corrected Agreement Coefficient for “raw” ratings.</p>
<p>The functions in this module calculate chance-corrected agreement coefficients
using “raw” data, i.e., tables where each row represents a subject and each
column a rater. Each shell has the rating category.</p>
<div class="admonition-examples admonition">
<p class="admonition-title">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">irrCAC.datasets</span> <span class="kn">import</span> <span class="n">raw_4raters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">irrCAC.raw</span> <span class="kn">import</span> <span class="n">CAC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">raw_4raters</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  
<span class="go">       Rater1  Rater2  Rater3  Rater4</span>
<span class="go">Units</span>
<span class="go">1         1.0     1.0     NaN     1.0</span>
<span class="go">2         2.0     2.0     3.0     2.0</span>
<span class="go">3         3.0     3.0     3.0     3.0</span>
<span class="go">4         3.0     3.0     3.0     3.0</span>
<span class="go">5         2.0     2.0     2.0     2.0</span>
<span class="go">6         1.0     2.0     3.0     4.0</span>
<span class="go">7         4.0     4.0     4.0     4.0</span>
<span class="go">8         1.0     1.0     2.0     1.0</span>
<span class="go">9         2.0     2.0     2.0     2.0</span>
<span class="go">10        NaN     5.0     5.0     5.0</span>
<span class="go">11        NaN     NaN     1.0     1.0</span>
<span class="go">12        NaN     NaN     3.0     NaN</span>
</pre></div>
</div>
<p>Initialize a CAC object with the data frame of the ratings.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cac4raters</span> <span class="o">=</span> <span class="n">CAC</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cac4raters</span><span class="o">.</span><span class="n">gwet</span><span class="p">())</span>  
<span class="go">{&#39;est&#39;: {&#39;coefficient_value&#39;: 0.77544,</span>
<span class="go">         &#39;coefficient_name&#39;: &#39;AC1&#39;,</span>
<span class="go">         &#39;confidence_interval&#39;: (0.46081, 1),</span>
<span class="go">         &#39;p_value&#39;: 0.00021,</span>
<span class="go">         &#39;z&#39;: 5.42458,</span>
<span class="go">         &#39;se&#39;: 0.14295,</span>
<span class="go">         &#39;pa&#39;: 0.81818,</span>
<span class="go">         &#39;pe&#39;: 0.19032},</span>
<span class="go">&#39;weights&#39;: array([[1., 0., 0., 0., 0.],</span>
<span class="go">                  [0., 1., 0., 0., 0.],</span>
<span class="go">                  [0., 0., 1., 0., 0.],</span>
<span class="go">                  [0., 0., 0., 1., 0.],</span>
<span class="go">                  [0., 0., 0., 0., 1.]]),</span>
<span class="go">&#39;categories&#39;: [1.0, 2.0, 3.0, 4.0, 5.0]}</span>
</pre></div>
</div>
<p>Get results for any available method in the class with the same data.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cac4raters</span><span class="o">.</span><span class="n">fleiss</span><span class="p">())</span>  
<span class="go">{&#39;est&#39;: {&#39;coefficient_value&#39;: 0.76117,</span>
<span class="go">         &#39;coefficient_name&#39;: &quot;Fleiss&#39; kappa&quot;,</span>
<span class="go">         &#39;confidence_interval&#39;: (0.42438, 1),</span>
<span class="go">         &#39;p_value&#39;: 0.00042,</span>
<span class="go">         &#39;z&#39;: 4.97434,</span>
<span class="go">         &#39;se&#39;: 0.15302,</span>
<span class="go">         &#39;pa&#39;: 0.81818,</span>
<span class="go">         &#39;pe&#39;: 0.23872},</span>
<span class="go">&#39;weights&#39;: array([[1., 0., 0., 0., 0.],</span>
<span class="go">                  [0., 1., 0., 0., 0.],</span>
<span class="go">                  [0., 0., 1., 0., 0.],</span>
<span class="go">                  [0., 0., 0., 1., 0.],</span>
<span class="go">                  [0., 0., 0., 0., 1.]]),</span>
<span class="go">&#39;categories&#39;: [1.0, 2.0, 3.0, 4.0, 5.0]}</span>
</pre></div>
</div>
<p>To use weights with the calculations, we pass the type of weights as argument.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cac4raters_bipolar</span> <span class="o">=</span> <span class="n">CAC</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;bipolar&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cac4raters_bipolar</span><span class="o">.</span><span class="n">gwet</span><span class="p">())</span>  
<span class="go">{&#39;est&#39;: {&#39;coefficient_value&#39;: 0.90037,</span>
<span class="go">         &#39;coefficient_name&#39;: &#39;AC2&#39;,</span>
<span class="go">         &#39;confidence_interval&#39;: (0.66747, 1),</span>
<span class="go">         &#39;p_value&#39;: 0.0,</span>
<span class="go">         &#39;z&#39;: 8.50888,</span>
<span class="go">         &#39;se&#39;: 0.10582,</span>
<span class="go">         &#39;pa&#39;: 0.96836,</span>
<span class="go">         &#39;pe&#39;: 0.68244},</span>
<span class="go">&#39;weights&#39;: array([[1.        , 0.85714286, 0.66666667, 0.4       , 0.        ],</span>
<span class="go">                  [0.85714286, 1.        , 0.93333333, 0.75      , 0.4       ],</span>
<span class="go">                  [0.66666667, 0.93333333, 1.        , 0.93333333, 0.66666667],</span>
<span class="go">                  [0.4       , 0.75      , 0.93333333, 1.        , 0.85714286],</span>
<span class="go">                  [0.        , 0.4       , 0.66666667, 0.85714286, 1.        ]]),</span>
<span class="go">&#39;categories&#39;: [1.0, 2.0, 3.0, 4.0, 5.0]}</span>
</pre></div>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="irrCAC.raw.CAC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">irrCAC.raw.</span></span><span class="sig-name descname"><span class="pre">CAC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ratings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'identity'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categories</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">inf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">digits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.raw.CAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Chance-corrected Agreement Coefficients (CAC)</p>
<p>Calculates various chance-corrected agreement coefficients (CAC) among 2 or
more raters are provided. Among the CAC coefficients covered are</p>
<ul class="simple">
<li><p>Brennan-Prediger coefficient, (TODO)</p></li>
<li><p>Conger’s kappa, (TODO)</p></li>
<li><p>Fleiss’ kappa,</p></li>
<li><p>Gwet’s AC1/AC2 coefficients, and</p></li>
<li><p>Krippendorff’s alpha. (TODO)</p></li>
</ul>
<p>Multiple sets of weights are proposed for computing weighted analyses.
All of these statistical procedures are described in details in [1].</p>
<p>[1] Gwet, K.L. (2014, ISBN:978-0970806284): <em>“Handbook of Inter-Rater
Reliability”</em>, 4th edition, Advanced Analytics, LLC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ratings</strong> (<em>DataFrame</em>) – A data frame of ratings where each column represents one rater and
each row one subject.</p></li>
<li><p><strong>weights</strong> (<em>array-like</em><em>, </em><em>ndarray</em><em>, or </em><em>str</em><em>, </em><em>{&quot;identity&quot;</em><em>, </em><em>&quot;quadratic&quot;</em><em>, </em><em>&quot;ordinal&quot;</em><em>,    </em><em>&quot;linear&quot;</em><em>, </em><em>&quot;radical&quot;</em><em>, </em><em>&quot;ratio&quot;</em><em>, </em><em>&quot;circular&quot;</em><em>, </em><em>&quot;bipolar&quot;}</em>) – A mandatory parameter that is either a string variable or a matrix.
The string describes one of the predefined weights. If this
parameter is a matrix then it must be a square matrix qxq where q
is the number of possible categories where a subject can be
classified. If some of the q possible categories are not used,
then it is strongly advised to specify the complete list of
possible categories as a vector in parameter <code class="docutils literal notranslate"><span class="pre">categories</span></code>.
Otherwise, the program may not work.</p></li>
<li><p><strong>categories</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>default None</em>) – An optional vector parameter containing the list of all possible
ratings. It may be useful in case some possible ratings are not
used by any rater, they will still be used when calculating
agreement coefficients. The default value is None. In this case,
only categories reported by the raters are used in the calculations.</p></li>
<li><p><strong>confidence_level</strong> (<em>float</em><em>, </em><em>default 0.95</em>) – An optional parameter representing the confidence level associated
with the confidence interval. Its default value is 0.95.</p></li>
<li><p><strong>N</strong> (<em>int</em><em>, </em><em>default infinity</em>) – An optional parameter representing the population size (if any).
It may be used to perform the final population correction to the
variance. Its default value is infinity.</p></li>
<li><p><strong>digits</strong> (<em>int</em><em>, </em><em>default 5</em>) – The number of digits to round the results.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.raw.CAC.fleiss">
<span class="sig-name descname"><span class="pre">fleiss</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.raw.CAC.fleiss" title="Permalink to this definition">¶</a></dt>
<dd><p>Fleiss’ generalized kappa coefficient.</p>
<p>Fleiss’ defined the percent chance agreement the probability that any
pair of raters classify a subject into the same category.</p>
<p>The calculation of the kappa coefficient here takes into account any
missing values.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.raw.CAC.gwet">
<span class="sig-name descname"><span class="pre">gwet</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.raw.CAC.gwet" title="Permalink to this definition">¶</a></dt>
<dd><p>Gwet’s AC1/AC2 coefficient.</p>
<p>The AC1 coefficient was suggested by Gwet (2008a) as a paradox-resistant
alternative to Cohen’s Kappa. The percent chance agreement it is
defined as the propensity for raters to agree on hard-to-score
subjects and is calculated by multiplying the probability to agree
when the rating is random by the probability to select a
hard-to-score subject.</p>
<p>The Gwet’s AC2 coefficient is the one when using weight for the
calculation.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-irrCAC.table">
<span id="irrcac-table-module"></span><h2>irrCAC.table module<a class="headerlink" href="#module-irrCAC.table" title="Permalink to this headline">¶</a></h2>
<p>Chance-corrected Agreement Coefficient for tabular ratings.</p>
<div class="admonition-examples admonition">
<p class="admonition-title">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">irrCAC.datasets</span> <span class="kn">import</span> <span class="n">table_cont3x3abstractors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">irrCAC.table</span> <span class="kn">import</span> <span class="n">CAC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">table_cont3x3abstractors</span><span class="p">()</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">         Ectopic  AIU  NIU</span>
<span class="go">Ectopic       13    0    0</span>
<span class="go">AIU            0   20    7</span>
<span class="go">NIU            0    4   56</span>
</pre></div>
</div>
<p>Initialize a CAC object with the data from the contigency table</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cont3x3abstractors</span> <span class="o">=</span> <span class="n">CAC</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cont3x3abstractors</span><span class="o">.</span><span class="n">gwet</span><span class="p">())</span>  
<span class="go">&#39;est&#39;: {&#39;coefficient_value&#39;: 0.84933,</span>
<span class="go">        &#39;coefficient_name&#39;: &quot;Gwet&#39;s AC1&quot;,</span>
<span class="go">        &#39;confidence_interval&#39;: (0.76358, 0.93508),</span>
<span class="go">        &#39;p_value&#39;: 0.0,</span>
<span class="go">        &#39;z&#39;: 19.65248,</span>
<span class="go">        &#39;se&#39;: 0.04322,</span>
<span class="go">        &#39;pa&#39;: 0.89,</span>
<span class="go">        &#39;pe&#39;: 0.26992},</span>
<span class="go">&#39;weights&#39;: array([[1., 0., 0.],</span>
<span class="go">                  [0., 1., 0.],</span>
<span class="go">                  [0., 0., 1.]]),</span>
<span class="go">&#39;categories&#39;: [&#39;Ectopic&#39;, &#39;AIU&#39;, &#39;NIU&#39;]}</span>
</pre></div>
</div>
<p>To use weights with the calculations, we pass the type of weights as argument.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cont3x3abstractors_quadratic</span> <span class="o">=</span> <span class="n">CAC</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;quadratic&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cont3x3abstractors_quadratic</span><span class="o">.</span><span class="n">gwet</span><span class="p">())</span>  
<span class="go">{&#39;est&#39;: {&#39;coefficient_value&#39;: 0.94024,</span>
<span class="go">         &#39;coefficient_name&#39;: &quot;Gwet&#39;s AC2&quot;,</span>
<span class="go">         &#39;confidence_interval&#39;: (0.90468, 0.97579),</span>
<span class="go">         &#39;p_value&#39;: 0.0,</span>
<span class="go">         &#39;z&#39;: 52.46802,</span>
<span class="go">         &#39;se&#39;: 0.01792,</span>
<span class="go">         &#39;pa&#39;: 0.9725,</span>
<span class="go">         &#39;pe&#39;: 0.53985},</span>
<span class="go">&#39;weights&#39;: array([[1.  , 0.75, 0.  ],</span>
<span class="go">                  [0.75, 1.  , 0.75],</span>
<span class="go">                  [0.  , 0.75, 1.  ]]),</span>
<span class="go">&#39;categories&#39;: [&#39;Ectopic&#39;, &#39;AIU&#39;, &#39;NIU&#39;]}</span>
</pre></div>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="irrCAC.table.CAC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">irrCAC.table.</span></span><span class="sig-name descname"><span class="pre">CAC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ratings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'identity'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">inf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">digits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.table.CAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Chance-corrected Agreement Coefficients (CAC)</p>
<p>Calculates various chance-corrected agreement coefficients (CAC) among 2 or
more raters are provided. Among the CAC coefficients covered are</p>
<ul class="simple">
<li><p>Brennan-Prediger coefficient,</p></li>
<li><p>Cohen’s kappa,</p></li>
<li><p>Conger’s kappa, (TODO)</p></li>
<li><p>Fleiss’ kappa, (TODO)</p></li>
<li><p>Gwet’s AC1/AC2 coefficients, and</p></li>
<li><p>Krippendorff’s alpha. (TODO)</p></li>
</ul>
<p>Multiple sets of weights are proposed for computing weighted analyses.
All of these statistical procedures are described in details in Gwet, K.L.
(2014,ISBN:978-0970806284): “Handbook of Inter-Rater Reliability,”
4th edition, Advanced Analytics, LLC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ratings</strong> (<em>DataFrame</em>) – A data frame of ratings where each column represents one rater and
each row one subject.</p></li>
<li><p><strong>weights</strong> (<em>array-like</em><em>, </em><em>ndarray</em><em>, or </em><em>str</em><em>, </em><em>{&quot;identity&quot;</em><em>, </em><em>&quot;quadratic&quot;</em><em>, </em><em>&quot;ordinal&quot;</em><em>,    </em><em>&quot;linear&quot;</em><em>, </em><em>&quot;radical&quot;</em><em>, </em><em>&quot;ratio&quot;</em><em>, </em><em>&quot;circular&quot;</em><em>, </em><em>&quot;bipolar&quot;}</em>) – A mandatory parameter that is either a string variable or a matrix.
The string describes one of the predefined weights. If this
parameter is a matrix then it must be a square matrix qxq where q
is the number of possible categories where a subject can be
classified. If some of the q possible categories are not used,
then it is strongly advised to specify the complete list of
possible categories as a vector in parameter <code class="docutils literal notranslate"><span class="pre">categories</span></code>.
Otherwise, the program may not work.</p></li>
<li><p><strong>confidence_level</strong> (<em>float</em><em>, </em><em>default 0.95</em>) – An optional parameter representing the confidence level associated
with the confidence interval. Its default value is 0.95.</p></li>
<li><p><strong>N</strong> (<em>int</em><em>, </em><em>default infinity</em>) – An optional parameter representing the population size (if any).
It may be used to perform the final population correction to the
variance. Its default value is infinity.</p></li>
<li><p><strong>digits</strong> (<em>int</em><em>, </em><em>default 5</em>) – The number of digits to round the results.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.table.CAC.bp">
<span class="sig-name descname"><span class="pre">bp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.table.CAC.bp" title="Permalink to this definition">¶</a></dt>
<dd><p>Brennan-Prediger coefficient.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.table.CAC.cohen">
<span class="sig-name descname"><span class="pre">cohen</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.table.CAC.cohen" title="Permalink to this definition">¶</a></dt>
<dd><p>Cohen’s kappa coefficient.</p>
<p>Cohen’s kappa measures the agreement between two raters who each
classify N subjects into <span class="math notranslate nohighlight">\(q\)</span> mutually exclusive categories.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.table.CAC.gwet">
<span class="sig-name descname"><span class="pre">gwet</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.table.CAC.gwet" title="Permalink to this definition">¶</a></dt>
<dd><p>Gwet’s AC1/AC2 coefficient.</p>
<p>The AC1 coefficient was suggested by Gwet (2008a) as a paradox-resistant
alternative to Cohen’s Kappa. The percent chance agreement it is
defined as the propensity for raters to agree on hard-to-score
subjects and is calculated by multiplying the probability to agree
when the rating is random by the probability to select a
hard-to-score subject.</p>
<p>The Gwet’s AC2 coefficient is the one when using weight for the
calculation.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-irrCAC.weights">
<span id="irrcac-weights-module"></span><h2>irrCAC.weights module<a class="headerlink" href="#module-irrCAC.weights" title="Permalink to this headline">¶</a></h2>
<p>A set of predefined weight schemes that can be used with the agreement coefficients.</p>
<dl class="py class">
<dt class="sig sig-object py" id="irrCAC.weights.Weights">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">irrCAC.weights.</span></span><span class="sig-name descname"><span class="pre">Weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">categories</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Methods for computing weights for a set of categories.</p>
<p>The class can compute weights, using the methods:</p>
<ul class="simple">
<li><p>bipolar</p></li>
<li><p>circular</p></li>
<li><p>identity</p></li>
<li><p>linear</p></li>
<li><p>ordinal</p></li>
<li><p>quadratic</p></li>
<li><p>radial</p></li>
<li><p>ratio</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.bipolar">
<span class="sig-name descname"><span class="pre">bipolar</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.bipolar" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Bipolar Weights</p>
<p>Bipolar weights of a matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
<span class="math notranslate nohighlight">\(q\)</span> is the number of <cite>categories</cite>, are defined for each cell
<span class="math notranslate nohighlight">\(w_{kl}, (k,l=1, \ldots, q)\)</span> by</p>
<div class="math notranslate nohighlight">
\[w_{kl} = \frac{(k - l)^2}{
    ((k + l - 2 \cdot \min(c))(2 \cdot \max(c) - k - l))}\]</div>
<p>where <span class="math notranslate nohighlight">\(c \in R^q\)</span> is the vector of the <cite>categories</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of bipolar weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.circular">
<span class="sig-name descname"><span class="pre">circular</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.circular" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Circular Weights</p>
<p>Circular weights of a matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
<span class="math notranslate nohighlight">\(q\)</span> is the number of <cite>categories</cite>, are defined for each cell
<span class="math notranslate nohighlight">\(w_{kl}, (k,l=1, \ldots, q)\)</span> by</p>
<div class="math notranslate nohighlight">
\[w_{kl} = \sin(\frac{\pi (k - l)}{(\max(c) - \min(c) + 1)})^2\]</div>
<p>where <span class="math notranslate nohighlight">\(c \in R^q\)</span> is the vector of the <cite>categories</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of circular weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.identity">
<span class="sig-name descname"><span class="pre">identity</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.identity" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Identity Weights.</p>
<p>The identity weighted matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
<span class="math notranslate nohighlight">\(q\)</span> is the number of <cite>categories</cite>, is the same as to calculate the
coefficients without weights (unweighted). The weights are defined as
<span class="math notranslate nohighlight">\(w_{kk}=1, (k=1, \ldots, q)\)</span> and
<span class="math notranslate nohighlight">\(w_{kl}=0, (k,l=1, \ldots, q)\)</span> if <span class="math notranslate nohighlight">\(k \neq l\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of identity weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.linear">
<span class="sig-name descname"><span class="pre">linear</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Linear Weights.</p>
<p>Linear weights of a matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
math:<cite>q</cite> is the number of <cite>categories</cite>, are defined for each cell
<span class="math notranslate nohighlight">\(w_{kl}, (k,l=1, \ldots, q)\)</span> by</p>
<div class="math notranslate nohighlight">
\[w_{kl} = 1 - \frac{|k - l|}{q - 1}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of linear weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.ordinal">
<span class="sig-name descname"><span class="pre">ordinal</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.ordinal" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Ordinal Weights</p>
<p>Ordinal weights of a matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
<span class="math notranslate nohighlight">\(q\)</span> is the number of <cite>categories</cite>, are defined for each cell
<span class="math notranslate nohighlight">\(w_{kl}, (k,l=1, \ldots, q)\)</span> by</p>
<div class="math notranslate nohighlight">
\[w_{kl} = \frac{(\max(k, l) - \min(k, l) + 1) \cdot
         (\max(k, l) - \min(k, l))}{2}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of ordinal weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.quadratic">
<span class="sig-name descname"><span class="pre">quadratic</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.quadratic" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Quadratic Weights</p>
<p>Quadratic weights of a matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
<span class="math notranslate nohighlight">\(q\)</span> is the number of <cite>categories</cite>, are defined for each cell
<span class="math notranslate nohighlight">\(w_{kl}, (k,l=1, \ldots, q)\)</span> by</p>
<div class="math notranslate nohighlight">
\[w_{kl} = 1 - \frac{(k - l)^2}{(q - 1)^2}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of quadratic weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.radical">
<span class="sig-name descname"><span class="pre">radical</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.radical" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Radical Weights</p>
<p>Radical weights of a matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
<span class="math notranslate nohighlight">\(q\)</span> is the number of <cite>categories</cite>, are defined for each cell
<span class="math notranslate nohighlight">\(w_{kl}, (k,l=1, \ldots, q)\)</span> by</p>
<div class="math notranslate nohighlight">
\[w_{kl} = 1 - \frac{|k - l|^{1/2}}{(\max(c) - \min(c))^{1/2}}\]</div>
<p>where <span class="math notranslate nohighlight">\(c \in R^q\)</span> is the vector of the <cite>categories</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of radical weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="irrCAC.weights.Weights.ratio">
<span class="sig-name descname"><span class="pre">ratio</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#irrCAC.weights.Weights.ratio" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for computing the Ratio Weights</p>
<p>Ratio weights of a matrix <span class="math notranslate nohighlight">\(W \in R^{q \times q}\)</span>, where
<span class="math notranslate nohighlight">\(q\)</span> is the number of <cite>categories</cite>, are defined for each cell
<span class="math notranslate nohighlight">\(w_{kl}, (k,l=1, \ldots, q)\)</span> by</p>
<div class="math notranslate nohighlight">
\[w_{kl} = 1 - (\frac{k - l}{k + l})^2/(
    \frac{\max(c) - \min(c)}{\max(c) - \min(c)})^2\]</div>
<p>where <span class="math notranslate nohighlight">\(c \in R^q\)</span> is the vector of the <cite>categories</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A square matrix of ratio weights to be used for calculating the
weighted coefficients.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>2D <span class="math notranslate nohighlight">\(q \times q\)</span> matrix</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>ValueError</strong> – In cases we have the 0 as a category. This will produce a division
    by zero error.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">irrCAC</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">irrCAC</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">irrCAC package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="modules.html">irrCAC</a><ul>
      <li>Previous: <a href="modules.html" title="previous chapter">irrCAC</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Kilem Gwet, Aris Fergadis.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.3.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/irrCAC.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>